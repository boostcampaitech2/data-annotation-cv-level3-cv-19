{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h24KpW2YL9Cm"
   },
   "source": [
    "## 캠퍼분들과 함께 만든 dataset annotation수정, 디버깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2pR_L1BHL9Co"
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_mkdir(x):\n",
    "    if not osp.exists(x):\n",
    "        os.makedirs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eO7OcR7bL9Cp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1650/1650 [00:00<00:00, 13059.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal polygon count : 29643\n",
      "deleted 980 over polygon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "add_data_dir = '/opt/ml/input/data/camper'\n",
    "# 여기 부분 가지고 계신 폴더구성에 맞추어 수정해주시구요\n",
    "\n",
    "with open(osp.join(add_data_dir, 'ufo/{}.json'.format('annotation')), 'r') as f:\n",
    "# 여기 부분도 가지고 계신 파일명에 맞추어서 수정해주시길 요청드립니다.\n",
    "    anno = json.load(f)\n",
    "# illegibility는 전부 단어 이므로 false\n",
    "anno = anno['images']\n",
    "\n",
    "anno_temp = copy.deepcopy(anno)\n",
    "\n",
    "count = 0\n",
    "count_normal = 0\n",
    "count_none_anno = 0\n",
    "\n",
    "for img_name, img_info in tqdm(anno.items()) :\n",
    "    if img_info['words'] == {} :\n",
    "        del(anno_temp[img_name])\n",
    "        count_none_anno += 1\n",
    "        continue\n",
    "    for obj, obj_info in img_info['words'].items() :\n",
    "        # revised 버전일 경우 여기를 지워주세요\n",
    "        #anno_temp[img_name]['words'][obj]['illegibility'] = False\n",
    "        \n",
    "        if len(img_info['words'][obj]['points']) == 4 :\n",
    "            count_normal += 1\n",
    "            continue\n",
    "        # 폴리곤 수정시에는 여기 부분을 수정해주시면 됩니다!!\n",
    "        # 다음 예제는 polygon이 넘치거나 모자를 경우 해당 폴리곤을 object를 삭제처리\n",
    "        elif len(img_info['words'][obj]['points']) < 4 :\n",
    "            del(anno_temp[img_name]['words'][obj])\n",
    "            if anno_temp[img_name]['words'] == {} :\n",
    "                del(anno_temp[img_name])\n",
    "                count_none_anno += 1\n",
    "                continue\n",
    "        else :\n",
    "            # 현동님의 기여로 만들어진 부분\n",
    "            over_polygon_temp = copy.deepcopy(anno_temp[img_name]['words'][obj])\n",
    "            over_poly_region = copy.deepcopy(over_polygon_temp)\n",
    "            over_poly_region['points'] = []\n",
    "            for index in range(len(img_info['words'][obj]['points'])//2 -1):\n",
    "                over_poly_region['points'].append(over_polygon_temp['points'][index])\n",
    "                over_poly_region['points'].append(over_polygon_temp['points'][index+1])\n",
    "                over_poly_region['points'].append(over_polygon_temp['points'][-index-1])\n",
    "                over_poly_region['points'].append(over_polygon_temp['points'][-index])\n",
    "                anno_temp[img_name]['words'][obj+f'{index+911}'] = copy.deepcopy(over_poly_region) #911 현동님 생일 >_<\n",
    "                over_poly_region['points'] = []\n",
    "            del anno_temp[img_name]['words'][obj]\n",
    "            # 폴리곤을 사각단위로 잘라서 각 부분을 word의 영역으로 사용하는 코드입니다.\n",
    "            if anno_temp[img_name]['words'] == {} :\n",
    "                del(anno_temp[img_name])\n",
    "                count_none_anno += 1\n",
    "                continue\n",
    "            count += 1\n",
    "            \n",
    "print(f'normal polygon count : {count_normal}')\n",
    "print(f'deleted {count} over polygon')\n",
    "\n",
    "anno = {'images': anno_temp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo_dir = osp.join('/opt/ml/input/data/camper', 'ufo')\n",
    "maybe_mkdir(ufo_dir)\n",
    "with open(osp.join(ufo_dir, 'train.json'), 'w') as f:\n",
    "    json.dump(anno, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OCR_EDA_revised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
